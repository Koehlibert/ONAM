---
output: 
  pdf_document:
    fig_width: 4
    fig_height: 3
header-includes:
  - \pagestyle{empty}
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

This file contains a brief tutorial on how to install and use the ONAM package.  

## Install package:
```{r install onam, eval = FALSE}
install.packages("devtools")  
library(devtools)  
devtools::install_github("Koehlibert/ONAM")
```
If this is the first time using Keras or TensorFlow in R, you need to run `keras::install_keras()`.

The following packages are required for importing the data, machine learning and visualization:

```{r library calls}
library(ONAM)
library(mlbench)
library(MASS)
library(gbm)
library(e1071)
library(caret)
library(xgboost)
library(dplyr)
```

We demonstrate the use of the proposed algorithm by decomposing (i) the results
of a gradient boosting machine for the prediction of diabetes risk and (ii) the
results of an XGBoost\footnote[2]{\textcolor{red}{T. Chen, C. Guestrin, XGBoost: A scalable tree boosting system. in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD ’16) (eds, B. Krishnapuram et al.) (Association for Computing Machinery, New York, 2016), 785–794.\newline\newline\newline\newline\newline\newline}} model for the prediction of housing prices.

\newpage

# Gradient boosting machine for the prediction of diabetes risk using the Salt River Pima-Maricopa Indian Community of the Salt River Reservation, Arizona Diabetes Database

Load the data:

```{r load diabetes data}
data(PimaIndiansDiabetes)
diabetes_data <- PimaIndiansDiabetes %>%
  mutate(diabetes = ifelse(diabetes == "pos", 1, 0)) %>%
  mutate(across(!diabetes, as.numeric)) %>%
  filter(mass > 0)

head(diabetes_data)
```

The data consist of `r nrow(diabetes_data)` observations of multiple medical
features as well as the diabetes status.

There are `r sum(diabetes_data$diabetes == 1)` diabetes cases and `r sum(diabetes_data$diabetes == 0)` controls in the data.

We demonstrate how to use ONAM to explain a gradient boosting machine for the prediction of diabetes status.

First, we fit a gradient boosting machine for binary classification.

```{r Diabetes gbm, echo = TRUE}
# Train the GBM model (binary classification)
gbm_model <- gbm(diabetes ~ .,
                 data = diabetes_data,
                 distribution = "bernoulli",  
                 n.trees = 500,               
                 interaction.depth = 3,       
                 shrinkage = 0.01,           
                 cv.folds = 5) 
summary(gbm_model, plotit = F)
```

\newpage

Assessment of model performance:

```{r gbm performance, echo = FALSE}
predicted_status <- predict(gbm_model, diabetes_data, n.trees = 500)
caret::confusionMatrix(factor(as.numeric(predicted_status > 0.5)), 
                       factor(diabetes_data$diabetes))
```

\newpage

## Fit ONAM model to decompose gbm predictions

We illustrate the use of the proposed algorithm by decomposing the predictions
of the fitted gbm model. By setting the `r "target"` parameter to `r "binary"`, a sigmoid activation function is applied to the last layer of the model, enabling the fitting of probability outcomes.

```{r diabetes onam model, echo = TRUE, results = "hide", eval = FALSE}
Diabetes_formula <- diabetes ~ mod(glucose) + mod(insulin) +
  mod(pregnant) + mod(pressure) + mod(triceps) +
  mod(pedigree) + mod(mass) + mod(age) + 
  mod(glucose, insulin) + mod(age, mass) + mod(.)
list_of_mods_Diabetes <- list(mod = ONAM:::get_submodel)
gbm_expl <- onam(
  Diabetes_formula,
  list_of_deep_models_Diabetes,
  diabetes_data,
  model = gbm_model,
  prediction_function = function(model, data) {
    predict(model, data, n.trees = 500, type = "response")
  },
  target = "binary", #use sigmoid activation in last layer
  n_ensemble = 10,
  progresstext = TRUE,
  epochs = 500,
  verbose = 0
)

#generate and save predictions
gbm_res <- predict(gbm_expl)
saveRDS(gbm_res, "gbm_res.RDS")

```

```{r diabetes model summary, echo = FALSE, eval = TRUE}
#Model building takes a lot of time, so we use pre-fitted models for knitting the pdf. To rerun the models, set eval=TRUE in ONAM fitting code chunks.
readRDS("diabetes_summary.rds")
```

```{r gbm diabetes plots, echo = FALSE}
gbm_res <- readRDS("gbm_res.RDS")
```

\newpage

### Visualization

All effects are presented on the logit scale.

A higher plasma glucose concentration is associated with a higher risk of
diabetes:

```{r pregnancy effect}
plot_main_effect(gbm_res, "glucose")
```

A higher BMI is associated with a higher risk of diabetes, but the increase is
lower in people of younger age:

```{r mass age effect, eval=FALSE}
plot_main_effect(gbm_res, "mass") + xlab("BMI")

plot_inter_effect(gbm_res, "age", "mass", interpolate = FALSE) +
    xlab("BMI") + ylab("Age")
```

```{r hidden plot library, echo = FALSE}
library(ggpubr)
library(ggplot2)
```


```{r mass age effect combined, echo = FALSE, fig.width=7}
ggarrange(
  plot_main_effect(gbm_res, "mass") + xlab("BMI"),
  plot_inter_effect(gbm_res, "age", "mass",
                    interpolate = FALSE) +
    xlab("BMI") + ylab("Age") +
    theme(legend.position = "right"),
  ncol = 2,
  widths = c(0.35, 0.65)
) 
```


\newpage

# XGBoost model for the prediction of housing prices using the Boston Housing Data

Load the data:

```{r load Boston data}
data("Boston")

head(Boston)
```

The dataset contains information on `r nrow(Boston)` census tracts. We use
XGBoost to fit a prediction model for median housing price per census tract.

```{r fit xgboost model}
train_Boston <- Boston %>% dplyr::select(-medv)
label_Boston <- Boston %>% dplyr::select(medv) %>% unlist()

xgb_train_Boston <- xgb.DMatrix(as.matrix(train_Boston),
                                   label = label_Boston)

xgb_mod <-
  xgboost(
    xgb_train_Boston,
    nrounds = 10000,
    verbose = 0,
    objective = "reg:squarederror",
    eval_metric = "rmse"
  )
summary(xgb_mod)

preds <- predict(xgb_mod, xgb_train_Boston)
pricing_cor <- cor(preds, Boston$medv)
```

Correlation between housing prices and predictions: `r round(pricing_cor, 4)`

## Fit ONAM model to decompose XGBoost predictions

We illustrate the use of the proposed algorithm by decomposing the predictions
of the fitted XGBoost model:

```{r onam insurance, echo = TRUE, echo = TRUE, results = "hide", eval = FALSE}
Boston_formula <-
  medv ~ mod(crim) + mod(zn) + mod(indus) + mod(chas) +
  mod(nox) + mod(rm) + mod(age) + mod(dis) + mod(rad) +
  mod(tax) + mod(ptratio) + mod(black) + mod(lstat) +
  mod(crim, dis) + mod(rm, age) + mod(zn, indus) +
  mod(.)

list_of_deep_models_Boston <- list(mod = ONAM:::get_submodel)

categorical_features <- c("chas")

xgb_expl <-
  onam(
    Boston_formula,
    list_of_deep_models_Boston,
    Boston,
    model = xgb_mod,
    model_data = xgb_train_Boston,
    categorical_features = categorical_features,
    n_ensemble = 20,
    epochs = 1000,
    progresstext = TRUE,
    verbose = 0
  )

xgb_res <- predict(xgb_expl)
saveRDS(xgb_res, "xgb_res.RDS")
```

```{r xgb summary Boston, echo=FALSE}
readRDS("xgb_summary.rds")
```

```{r load and plot xgb onam model, echo=FALSE}
xgb_res <- readRDS("xgb_res.RDS")
```

\newpage

### Visualization

Higher crime rate is associated with lower housing prices:

```{r crime effect}
plot_main_effect(xgb_res, "crim") + xlab("Crime rate (%)")
```

Lower number of rooms is associated with lower housing prices, but less so in
(areas with) older houses:

```{r room effect, eval = FALSE}
plot_main_effect(xgb_res, "rm") + xlab("Av. number of rooms per dwelling")
plot_inter_effect(xgb_res, "rm", "age") + 
  xlab("Av. number of rooms per dwelling") + 
  ylab("% of units build prior to 1940")
```

```{r room effect combined, echo = FALSE, fig.width=7}
ggarrange(
  plot_main_effect(xgb_res, "rm") +
    xlab("Av. number of rooms per dwelling"),
  plot_inter_effect(xgb_res, "rm", "age") +
    xlab("Av. number of rooms per dwelling") +
    ylab("% of units build prior to 1940") +
    theme(legend.position = "right"),
  ncol = 2,
  widths = c(0.35, 0.65)
)
```
